{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03331bec",
   "metadata": {},
   "source": [
    "# Importing Important Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d21ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7c6078",
   "metadata": {},
   "source": [
    "# Function to compute technical indicators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deec9f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_technical_indicators(df):\n",
    "    df['SMA_10'] = df['Close'].rolling(window=10).mean()\n",
    "    df['SMA_30'] = df['Close'].rolling(window=30).mean()\n",
    "    df['EMA_12'] = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "    df['EMA_26'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    delta = df['Close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    rs = gain / loss\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "    df['MACD'] = df['EMA_12'] - df['EMA_26']\n",
    "    df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    df['BB_Middle'] = df['Close'].rolling(window=20).mean()\n",
    "    df['BB_Std'] = df['Close'].rolling(window=20).std()\n",
    "    df['BB_Upper'] = df['BB_Middle'] + 2 * df['BB_Std']\n",
    "    df['BB_Lower'] = df['BB_Middle'] - 2 * df['BB_Std']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01df0575",
   "metadata": {},
   "source": [
    "# Function to prepare data for LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f987f9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_lstm_data(X, y, time_steps=60):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:(i + time_steps)])\n",
    "        ys.append(y[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da49cf6",
   "metadata": {},
   "source": [
    "# Function to predict future values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77a74bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future(model, last_sequence, scaler_y, future_days, time_steps, n_components):\n",
    "    future_predictions = []  # Initialize the list to store future predictions\n",
    "    current_sequence = last_sequence.copy()  # Shape: (time_steps, n_components)\n",
    "\n",
    "    for _ in range(future_days):\n",
    "        # Reshape the sequence for the model (1, time_steps, n_components)\n",
    "        current_sequence_reshaped = current_sequence.reshape(1, time_steps, -1)\n",
    "        # Predict the next value (scaled)\n",
    "        next_pred_scaled = model.predict(current_sequence_reshaped, verbose=0)\n",
    "        # Inverse transform the prediction to original scale\n",
    "        next_pred = scaler_y.inverse_transform(next_pred_scaled)\n",
    "        future_predictions.append(next_pred[0, 0])\n",
    "\n",
    "        # Replicate the predicted scaled value across all PCA components to match shape\n",
    "        # This is an approximation since we can't predict PCA components directly\n",
    "        next_pred_scaled_replicated = np.repeat(next_pred_scaled, n_components, axis=1)  # Shape: (1, n_components)\n",
    "        # Update the sequence: remove the oldest time step, append the new \"PCA\" values\n",
    "        current_sequence = np.vstack((current_sequence[1:], next_pred_scaled_replicated))\n",
    "\n",
    "    return np.array(future_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf28a04",
   "metadata": {},
   "source": [
    "# Step 1: Fetch stock data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fc9d5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after fetching data: Index(['Close', 'High', 'Low', 'Open', 'Volume'], dtype='object', name='Price')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ticker = 'TSLA'\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=5*365)  # 5 years of data\n",
    "stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "\n",
    "# Ensure the DataFrame has a flat column structure\n",
    "if isinstance(stock_data.columns, pd.MultiIndex):\n",
    "    stock_data.columns = stock_data.columns.get_level_values(0)\n",
    "print(\"Columns after fetching data:\", stock_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8688869",
   "metadata": {},
   "source": [
    "# Step 2: Compute technical indicators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5a2aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data = compute_technical_indicators(stock_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6156c04b",
   "metadata": {},
   "source": [
    "# Step 3: Select features and handle missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d2d6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Open', 'High', 'Low', 'Close', 'Volume', 'SMA_10', 'SMA_30', \n",
    "            'EMA_12', 'EMA_26', 'RSI', 'MACD', 'MACD_Signal', \n",
    "            'BB_Middle', 'BB_Upper', 'BB_Lower']\n",
    "stock_data = stock_data[features].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2544b73c",
   "metadata": {},
   "source": [
    "# Step 4: Prepare features and target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3ac2ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = stock_data.drop(columns=['Close'])\n",
    "y = stock_data['Close'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22e8268",
   "metadata": {},
   "source": [
    "# Step 5: Standardize the features and target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "521b834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "# Scale the target variable (y)\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b44d16f",
   "metadata": {},
   "source": [
    "# Step 6: Apply PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ac703c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Select components explaining 85% of variance\n",
    "explained_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "n_components = np.argmax(explained_variance_ratio >= 0.85) + 1\n",
    "X_pca = X_pca[:, :n_components]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f39e21",
   "metadata": {},
   "source": [
    "# Step 7: Prepare data for LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcfa6f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 60\n",
    "X_lstm, y_lstm = prepare_lstm_data(X_pca, y_scaled, time_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8573e6e9",
   "metadata": {},
   "source": [
    "# Step 8: Split data into train and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53be70d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(X_lstm))\n",
    "X_train, X_test = X_lstm[:train_size], X_lstm[train_size:]\n",
    "y_train, y_test = y_lstm[:train_size], y_lstm[train_size:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a588fc8",
   "metadata": {},
   "source": [
    "# Step 9: Build LSTM model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "423c9e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(time_steps, n_components)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50),\n",
    "    Dropout(0.2),\n",
    "    Dense(25),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2330749b",
   "metadata": {},
   "source": [
    "# Step 10: Train the model with more epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea554581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.2683 - val_loss: 0.0301\n",
      "Epoch 2/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0793 - val_loss: 0.0350\n",
      "Epoch 3/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0719 - val_loss: 0.0288\n",
      "Epoch 4/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0635 - val_loss: 0.0252\n",
      "Epoch 5/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0654 - val_loss: 0.0290\n",
      "Epoch 6/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0751 - val_loss: 0.0230\n",
      "Epoch 7/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0511 - val_loss: 0.0205\n",
      "Epoch 8/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0582 - val_loss: 0.0296\n",
      "Epoch 9/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0532 - val_loss: 0.0193\n",
      "Epoch 10/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0509 - val_loss: 0.0200\n",
      "Epoch 11/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0481 - val_loss: 0.0223\n",
      "Epoch 12/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0474 - val_loss: 0.0184\n",
      "Epoch 13/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0511 - val_loss: 0.0179\n",
      "Epoch 14/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0442 - val_loss: 0.0197\n",
      "Epoch 15/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0427 - val_loss: 0.0174\n",
      "Epoch 16/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0398 - val_loss: 0.0179\n",
      "Epoch 17/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0417 - val_loss: 0.0162\n",
      "Epoch 18/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0438 - val_loss: 0.0175\n",
      "Epoch 19/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0381 - val_loss: 0.0191\n",
      "Epoch 20/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0432 - val_loss: 0.0162\n",
      "Epoch 21/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0427 - val_loss: 0.0176\n",
      "Epoch 22/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0407 - val_loss: 0.0189\n",
      "Epoch 23/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0345 - val_loss: 0.0187\n",
      "Epoch 24/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0383 - val_loss: 0.0187\n",
      "Epoch 25/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0365 - val_loss: 0.0186\n",
      "Epoch 26/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0432 - val_loss: 0.0152\n",
      "Epoch 27/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0384 - val_loss: 0.0158\n",
      "Epoch 28/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0349 - val_loss: 0.0152\n",
      "Epoch 29/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0399 - val_loss: 0.0145\n",
      "Epoch 30/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0369 - val_loss: 0.0166\n",
      "Epoch 31/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0392 - val_loss: 0.0157\n",
      "Epoch 32/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0389 - val_loss: 0.0173\n",
      "Epoch 33/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0396 - val_loss: 0.0170\n",
      "Epoch 34/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0299 - val_loss: 0.0195\n",
      "Epoch 35/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0401 - val_loss: 0.0144\n",
      "Epoch 36/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0354 - val_loss: 0.0150\n",
      "Epoch 37/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0315 - val_loss: 0.0172\n",
      "Epoch 38/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0356 - val_loss: 0.0151\n",
      "Epoch 39/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0325 - val_loss: 0.0152\n",
      "Epoch 40/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0344 - val_loss: 0.0155\n",
      "Epoch 41/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0344 - val_loss: 0.0137\n",
      "Epoch 42/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0339 - val_loss: 0.0143\n",
      "Epoch 43/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0320 - val_loss: 0.0172\n",
      "Epoch 44/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0305 - val_loss: 0.0135\n",
      "Epoch 45/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0297 - val_loss: 0.0147\n",
      "Epoch 46/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0344 - val_loss: 0.0151\n",
      "Epoch 47/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0334 - val_loss: 0.0144\n",
      "Epoch 48/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0312 - val_loss: 0.0140\n",
      "Epoch 49/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0292 - val_loss: 0.0171\n",
      "Epoch 50/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0287 - val_loss: 0.0148\n",
      "Epoch 51/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0294 - val_loss: 0.0152\n",
      "Epoch 52/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0312 - val_loss: 0.0157\n",
      "Epoch 53/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0312 - val_loss: 0.0141\n",
      "Epoch 54/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0319 - val_loss: 0.0134\n",
      "Epoch 55/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0294 - val_loss: 0.0126\n",
      "Epoch 56/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0274 - val_loss: 0.0135\n",
      "Epoch 57/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0258 - val_loss: 0.0136\n",
      "Epoch 58/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0345 - val_loss: 0.0167\n",
      "Epoch 59/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0305 - val_loss: 0.0140\n",
      "Epoch 60/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0329 - val_loss: 0.0163\n",
      "Epoch 61/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0274 - val_loss: 0.0148\n",
      "Epoch 62/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0314 - val_loss: 0.0129\n",
      "Epoch 63/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0271 - val_loss: 0.0138\n",
      "Epoch 64/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0293 - val_loss: 0.0132\n",
      "Epoch 65/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0267 - val_loss: 0.0134\n",
      "Epoch 66/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0276 - val_loss: 0.0130\n",
      "Epoch 67/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0329 - val_loss: 0.0132\n",
      "Epoch 68/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0292 - val_loss: 0.0120\n",
      "Epoch 69/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0252 - val_loss: 0.0146\n",
      "Epoch 70/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0278 - val_loss: 0.0121\n",
      "Epoch 71/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0281 - val_loss: 0.0136\n",
      "Epoch 72/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0262 - val_loss: 0.0134\n",
      "Epoch 73/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0253 - val_loss: 0.0162\n",
      "Epoch 74/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0283 - val_loss: 0.0151\n",
      "Epoch 75/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0274 - val_loss: 0.0183\n",
      "Epoch 76/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0269 - val_loss: 0.0158\n",
      "Epoch 77/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0269 - val_loss: 0.0215\n",
      "Epoch 78/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0295 - val_loss: 0.0175\n",
      "Epoch 79/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0269 - val_loss: 0.0159\n",
      "Epoch 80/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0258 - val_loss: 0.0141\n",
      "Epoch 81/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0251 - val_loss: 0.0133\n",
      "Epoch 82/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0274 - val_loss: 0.0157\n",
      "Epoch 83/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0306 - val_loss: 0.0139\n",
      "Epoch 84/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0264 - val_loss: 0.0134\n",
      "Epoch 85/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0273 - val_loss: 0.0131\n",
      "Epoch 86/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0256 - val_loss: 0.0130\n",
      "Epoch 87/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0273 - val_loss: 0.0174\n",
      "Epoch 88/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0293 - val_loss: 0.0151\n",
      "Epoch 89/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0252 - val_loss: 0.0131\n",
      "Epoch 90/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0244 - val_loss: 0.0175\n",
      "Epoch 91/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0254 - val_loss: 0.0158\n",
      "Epoch 92/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0235 - val_loss: 0.0148\n",
      "Epoch 93/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0258 - val_loss: 0.0127\n",
      "Epoch 94/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0233 - val_loss: 0.0144\n",
      "Epoch 95/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0256 - val_loss: 0.0155\n",
      "Epoch 96/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0228 - val_loss: 0.0143\n",
      "Epoch 97/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0255 - val_loss: 0.0245\n",
      "Epoch 98/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0252 - val_loss: 0.0131\n",
      "Epoch 99/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0193 - val_loss: 0.0152\n",
      "Epoch 100/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0250 - val_loss: 0.0128\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, \n",
    "                    validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eb6f3e",
   "metadata": {},
   "source": [
    "# Step 11: Make predictions on test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1c99c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_scaled = model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions and actual values\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_test_actual = scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35bd8af",
   "metadata": {},
   "source": [
    "# Step 12: Evaluate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e57874eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Data: 533.32\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test_actual, y_pred)\n",
    "print(f'Mean Squared Error on Test Data: {mse:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5260e984",
   "metadata": {},
   "source": [
    "# Step 13: Predict future values (e.g., 30 days into the future)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33191677",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_days = 30\n",
    "last_sequence = X_lstm[-1]  # Last sequence from the test data\n",
    "future_predictions = predict_future(model, last_sequence, scaler_y, future_days, time_steps, n_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65021f44",
   "metadata": {},
   "source": [
    "# Step 14: Prepare data for plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6a6868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_length = len(y_test_actual)\n",
    "future_x = np.arange(test_length, test_length + future_days)\n",
    "# Flatten y_pred to 1D since it's (n_samples, 1)\n",
    "y_pred_flat = y_pred.flatten()\n",
    "# Ensure future_predictions is 1D (it already is, but for clarity)\n",
    "future_predictions = future_predictions.flatten()\n",
    "# Concatenate the 1D arrays\n",
    "combined_predictions = np.concatenate([y_pred_flat, future_predictions])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7537365b",
   "metadata": {},
   "source": [
    "# Step 15: Plot results with future predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ee6049",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(np.arange(test_length), y_test_actual, label='Actual Price', color='blue')\n",
    "plt.plot(np.arange(test_length + future_days), combined_predictions, label='Predicted Price', color='orange', linestyle='--')\n",
    "plt.axvline(x=test_length, color='gray', linestyle='--', label='Start of Future Prediction')\n",
    "plt.title(f'{ticker} Stock Price Prediction with Future Forecast')\n",
    "plt.xlabel('Time (Days)')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.savefig('results/tsla_stock_price_prediction_with_future.png')  # Updated pathplt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84637d08",
   "metadata": {},
   "source": [
    "# Step 16: Plot explained variance ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bd6680",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(explained_variance_ratio, marker='o')\n",
    "plt.axhline(y=0.85, color='r', linestyle='--')\n",
    "plt.title('PCA Explained Variance Ratio')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.savefig('results/tsla_pca_variance.png')  # Updated pathplt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
